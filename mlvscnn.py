# -*- coding: utf-8 -*-
"""MLvsCNN

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-S9z0C1--yxZino740fPgzwKmstE6p2D

#**Project 5: CNN-Based Automatic Modulation Recognition**

**by Mustafa and Shahbaa**
"""

# Commented out IPython magic to ensure Python compatibility.
# Import all the necessary libraries
# %matplotlib inline
import os
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import pickle
import random
import sys
import kagglehub
import numpy as np
import glob
import os
# Configure TensorFlow/Keras
import tensorflow as tf
from tensorflow.keras import layers, models, callbacks
from tensorflow.keras.utils import to_categorical
# CRITICAL: Set image data format to 'channels_first'
# The RML2016.10a dataset shape is (2, 128) which corresponds to (Channels, Length).
# We force this setting so Convolution2D works correctly with this shape.
tf.keras.backend.set_image_data_format('channels_first')

# 1. Download the dataset
print("Downloading dataset via KaggleHub...")
path = kagglehub.dataset_download("gustavopolicarpo/rml201610a-dict")
print("Path to dataset files:", path)

# 2. Search for .pkl OR .dat files
dataset_files = glob.glob(os.path.join(path, "*.pkl")) + glob.glob(os.path.join(path, "*.dat"))

if not dataset_files:
    # Fallback: Search recursively if not found in top folder
    dataset_files = glob.glob(os.path.join(path, "**", "*.pkl"), recursive=True) + \
                    glob.glob(os.path.join(path, "**", "*.dat"), recursive=True)

if not dataset_files:
    raise FileNotFoundError("No dataset file (.pkl or .dat) found in the downloaded path!")

data_path = dataset_files[0]
print("Loading data from: {}".format(data_path))

# 3. Load the file
# We use encoding='latin1' because the dataset was originally pickled in Python 2
try:
    with open(data_path, 'rb') as f:
        Xd = pickle.load(f, encoding='latin1')
    print("Success: Dataset loaded!")
    print("Dataset keys sample: {}".format(list(Xd.keys())[:5]))
except Exception as e:
    print("Error loading pickle: {}".format(e))
    raise

# 4. Extract SNRs, Modulations and format data for the network (Original logic preserved)('QPSK', 10)
snrs, mods = map(lambda j: sorted(list(set(map(lambda x: x[j], Xd.keys())))), [1, 0])
X = []
lbl = []
for mod in mods:
    for snr in snrs:
        X.append(Xd[(mod, snr)])
        for i in range(Xd[(mod, snr)].shape[0]):
            lbl.append((mod, snr))
X = np.vstack(X)
print("Dataset setup complete. Shape: {}".format(X.shape))

# Partition the data into training and test sets
np.random.seed(2016)
n_examples = X.shape[0]
n_train = int(n_examples * 0.5) # Ensure integer for slicing
train_idx = np.random.choice(range(0, n_examples), size=n_train, replace=False)
test_idx = list(set(range(0, n_examples)) - set(train_idx))

X_train = X[train_idx]
X_test =  X[test_idx]

# Convert labels to one-hot encoding using Python 3 list comprehension
# We iterate through the indices and map them to the class list
def to_onehot(yy):
    return to_categorical(yy, num_classes=len(mods))

Y_train = to_onehot(list(map(lambda x: mods.index(lbl[x][0]), train_idx)))
Y_test = to_onehot(list(map(lambda x: mods.index(lbl[x][0]), test_idx)))

print("Train Shape:", X_train.shape)
print("Test Shape:", X_test.shape)

# Build VT-CNN2 Neural Net model using TensorFlow Keras
# Input: [N, 2, 128]
# Output: [N, 11] (One of the modulation classes)

in_shp = list(X_train.shape[1:])
classes = mods
dr = 0.5 # dropout rate (%)

model = models.Sequential()

# Reshape [N, 2, 128] to [N, 1, 2, 128] on input (treating as 1-channel image)
model.add(layers.Reshape((1, 2, 128), input_shape=in_shp))

# Layer 1
model.add(layers.ZeroPadding2D((0, 2), data_format='channels_first'))
model.add(layers.Conv2D(256, (1, 3), padding='valid', activation="relu", name="conv1", kernel_initializer='glorot_uniform', data_format='channels_first'))
model.add(layers.Dropout(dr))

# Layer 2
model.add(layers.ZeroPadding2D((0, 2), data_format='channels_first'))
model.add(layers.Conv2D(80, (2, 3), padding="valid", activation="relu", name="conv2", kernel_initializer='glorot_uniform', data_format='channels_first'))
model.add(layers.Dropout(dr))

# Flatten for Dense Layers
model.add(layers.Flatten())

# Dense 1
model.add(layers.Dense(256, activation='relu', kernel_initializer='he_normal', name="dense1"))
model.add(layers.Dropout(dr))

# Dense 2 (Output)
model.add(layers.Dense(len(classes), kernel_initializer='he_normal', name="dense2"))
model.add(layers.Activation('softmax'))

# Compile the model
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
model.summary()

# Perform training
epochs = 100     # number of epochs to train on
batch_size = 1024  # training batch size

filepath = 'convmodrecnets_CNN2_0.5.wts.h5'

# Modern Keras callbacks
my_callbacks = [
    callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=True, mode='auto'),
    callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=0, mode='auto')
]

history = model.fit(
    X_train,
    Y_train,
    batch_size=batch_size,
    epochs=epochs,
    verbose=2,
    validation_data=(X_test, Y_test),
    callbacks=my_callbacks
)

# Load the best weights once training is finished
model.load_weights(filepath)

score = model.evaluate(X_test, Y_test, verbose=0, batch_size=batch_size)
print("Test Loss:", score[0])
print("Test Accuracy:", score[1])
# Show loss curves
plt.figure(figsize=(7,6))
plt.title('Training performance')
plt.plot(history.epoch, history.history['loss'], label='train loss+error')
plt.plot(history.epoch, history.history['val_loss'], label='val_error')
plt.legend()
plt.show()

def plot_confusion_matrix(cm, title='Confusion matrix', cmap=plt.cm.Blues, labels=[]):
    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(labels))
    plt.xticks(tick_marks, labels, rotation=45)
    plt.yticks(tick_marks, labels)
    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label')
    plt.show()

# Plot confusion matrix
test_Y_hat = model.predict(X_test, batch_size=batch_size)
conf = np.zeros([len(classes),len(classes)])
confnorm = np.zeros([len(classes),len(classes)])

for i in range(0,X_test.shape[0]):
    j = list(Y_test[i,:]).index(1)
    k = int(np.argmax(test_Y_hat[i,:]))
    conf[j,k] = conf[j,k] + 1

for i in range(0,len(classes)):
    confnorm[i,:] = conf[i,:] / np.sum(conf[i,:])

plt.figure(figsize=(7,7))
plot_confusion_matrix(confnorm, labels=classes)

"""**1. The "WBFM vs. AM-DSB" Confusion**

In your image: Look at the bottom row (WBFM). There is a light blue square in the AM-DSB column. This means the AI often thinks Wideband FM is actually AM-DSB.

In the Paper: The authors explicitly predict this! They state: "In the case of WBFM/AM-DSB the analog voice signal has periods of silence where only a carrier tone is present making these examples indiscernible". Your model is making the exact same justifiable mistake.

**2. The "8PSK vs. QPSK" Confusion**

In your image: Look at the top row (8PSK). There is a faint blue square in the QPSK column.


In the Paper: The authors explain this too: "An 8PSK symbol... is indiscernible from QPSK since the QPSK constellation points are spanned by 8PSK points". Essentially, 8PSK looks like a more complicated version of QPSK, so the AI gets them mixed up.

**3. The QAM16 vs. QAM64 Confusion**

In your image: Look at the QAM16 and QAM64 rows. There is a large block of light blue mixing these two up.

Why: While the paper focuses on the other errors, this is expected in radio engineering. QAM64 is just a denser grid of points than QAM16. In noisy conditions (low SNR), it is mathematically very hard to tell if a point belongs to the "dense" grid (64) or the "sparse" grid (16).
"""

# Plot accuracy per SNR
acc = {}
for snr in snrs:

    # extract classes @ SNR
    # We map the labels back to the test_idx to find which specific samples belong to this SNR
    test_SNRs = list(map(lambda x: lbl[x][1], test_idx))
    test_X_i = X_test[np.where(np.array(test_SNRs)==snr)]
    test_Y_i = Y_test[np.where(np.array(test_SNRs)==snr)]

    # estimate classes
    test_Y_i_hat = model.predict(test_X_i)

    conf = np.zeros([len(classes),len(classes)])
    confnorm = np.zeros([len(classes),len(classes)])
    for i in range(0,test_X_i.shape[0]):
        j = list(test_Y_i[i,:]).index(1)
        k = int(np.argmax(test_Y_i_hat[i,:]))
        conf[j,k] = conf[j,k] + 1
    for i in range(0,len(classes)):
        confnorm[i,:] = conf[i,:] / np.sum(conf[i,:])
    plt.figure()
    plot_confusion_matrix(confnorm, labels=classes, title="ConvNet Confusion Matrix (SNR=%d)"%(snr))

    cor = np.sum(np.diag(conf))
    ncor = np.sum(conf) - cor
    print("SNR: ", snr, " Overall Accuracy: ", cor / (cor+ncor))
    acc[snr] = 1.0*cor/(cor+ncor)

# Plot accuracy per SNR
acc = {}
for snr in snrs:

    # extract classes @ SNR
    # We map the labels back to the test_idx to find which specific samples belong to this SNR
    test_SNRs = list(map(lambda x: lbl[x][1], test_idx))
    test_X_i = X_test[np.where(np.array(test_SNRs)==snr)]
    test_Y_i = Y_test[np.where(np.array(test_SNRs)==snr)]

    # estimate classes
    test_Y_i_hat = model.predict(test_X_i)

    # Calculate accuracy for this SNR
    conf = np.zeros([len(classes),len(classes)])
    confnorm = np.zeros([len(classes),len(classes)])

    for i in range(0,test_X_i.shape[0]):
        j = list(test_Y_i[i,:]).index(1)
        k = int(np.argmax(test_Y_i_hat[i,:]))
        conf[j,k] = conf[j,k] + 1

    for i in range(0,len(classes)):
        confnorm[i,:] = conf[i,:] / np.sum(conf[i,:])

    # Visualizing confusion matrix for specific SNRs (Optional, you can comment this out if too many plots)
    # plt.figure()
    # plot_confusion_matrix(confnorm, labels=classes, title="ConvNet Confusion Matrix (SNR=%d)"%(snr))

    cor = np.sum(np.diag(conf))
    ncor = np.sum(conf) - cor
    print("SNR: ", snr, " Overall Accuracy: ", cor / (cor+ncor))
    acc[snr] = 1.0*cor/(cor+ncor)

# Plot accuracy curve
plt.figure()
plt.plot(snrs, list(map(lambda x: acc[x], snrs))) # Fixed map() for Python 3
plt.xlabel("Signal to Noise Ratio")
plt.ylabel("Classification Accuracy")
plt.title("CNN2 Classification Accuracy on RadioML 2016.10 Alpha")
plt.show()

# Save results to a pickle file for plotting later
print(acc)
with open('results_cnn2_d0.5.dat','wb') as fd:
    pickle.dump( ("CNN2", 0.5, acc) , fd )

"""# **Classical ML**"""

# --- 1. Data Preprocessing for Classical ML ---
from sklearn.metrics import accuracy_score

# Flatten the 2x128 signals into 1D vectors of size 256
# CNN Input: (N, 2, 128) -> Classical Input: (N, 256)
X_train_flat = X_train.reshape((X_train.shape[0], -1))
X_test_flat = X_test.reshape((X_test.shape[0], -1))

# Convert One-Hot encoded labels back to single integer class indices
#The Problem: Scikit-Learn models (SVM, KNN, RF) cannot read "channels" or "time steps." They only understand a long list of numbers for each sample.
# Example: [0, 0, 1, 0] -> Class 2
Y_train_flat = np.argmax(Y_train, axis=1)
Y_test_flat = np.argmax(Y_test, axis=1)

print("New Training Shape:", X_train_flat.shape)
print("New Testing Labels Shape:", Y_test_flat.shape)

# --- 2. Train Classical Classifiers ---
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
import time

# Initialize models
models_ml = {
    'KNN': KNeighborsClassifier(n_neighbors=7),
    'SVM (RBF)': SVC(kernel='rbf', C=10, gamma='scale'), # RBF is better for non-linear radio data
    'Random Forest': RandomForestClassifier(n_estimators=100, n_jobs=-1) # n_jobs=-1 uses all CPU cores
}

ml_accuracy = {}

for name, clf in models_ml.items():
    print(f"Training {name}...")
    start = time.time()

    if name == 'SVM (RBF)':
        # SVM is too slow for 110k samples on CPU, training on a subset of 10k samples
        # This provides a decent approximation of performance without waiting hours
        subset_idx = np.random.choice(len(Y_train_flat), 10000, replace=False)
        clf.fit(X_train_flat[subset_idx], Y_train_flat[subset_idx])
    else:
        # KNN and RF can handle the full dataset
        clf.fit(X_train_flat, Y_train_flat)

    end = time.time()
    print(f"{name} Trained in {end-start:.2f} seconds")

print("All models trained.")

# --- 3. Evaluate Classical Models per SNR ---

# Initialize dictionary to store results for plotting
# Structure: {'KNN': {0: 0.5, 2: 0.6...}, 'SVM': ...}
ml_results = {name: {} for name in models_ml.keys()}

print("Evaluating models across SNRs...")

for snr in snrs:
    # Extract test samples belonging to this specific SNR
    test_SNRs = list(map(lambda x: lbl[x][1], test_idx))
    test_indices_snr = np.where(np.array(test_SNRs) == snr)[0]

    X_test_snr = X_test_flat[test_indices_snr]
    Y_test_snr = Y_test_flat[test_indices_snr]

    for name, clf in models_ml.items():
        # Predict
        pred = clf.predict(X_test_snr)

        # Calculate Accuracy
        acc = accuracy_score(Y_test_snr, pred)
        ml_results[name][snr] = acc

    print(f"SNR {snr}dB Completed")

print("Evaluation Complete.")

# --- 4. Plot Comparison: CNN vs Classical ML ---
import pickle

# Load CNN results from the previous file
# We saved it as a tuple: ("CNN2", 0.5, acc_dict)
try:
    with open('results_cnn2_d0.5.dat', 'rb') as f:
        cnn_data = pickle.load(f)
    cnn_acc = cnn_data[2] # The dictionary is the 3rd element
    print("Loaded CNN results successfully.")
except:
    print("Could not load CNN results. Ensure the file 'results_cnn2_d0.5.dat' exists.")
    cnn_acc = None

plt.figure(figsize=(10, 6))

# Plot Classical Models
for name, results in ml_results.items():
    # Sort by SNR key to ensure lines connect correctly
    sorted_snrs = sorted(results.keys())
    sorted_acc = [results[s] for s in sorted_snrs]
    plt.plot(sorted_snrs, sorted_acc, label=name, marker='o', linestyle='--')

# Plot CNN (if available)
if cnn_acc:
    sorted_snrs = sorted(cnn_acc.keys())
    sorted_acc = [cnn_acc[s] for s in sorted_snrs]
    plt.plot(sorted_snrs, sorted_acc, label='CNN (Proposed)', linewidth=3, color='black', marker='s')

plt.xlabel("Signal to Noise Ratio (dB)")
plt.ylabel("Classification Accuracy")
plt.title("Model Comparison: CNN vs Classical ML (Raw I/Q Data)")
plt.legend()
plt.grid(True, alpha=0.3)
plt.show()

"""# **Gradio**"""

import gradio as gr
import pickle
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

# --- 1. Load the Results ---
try:
    # Load CNN results
    # Ensure 'results_cnn2_d0.5.dat' is in the same folder
    with open('results_cnn2_d0.5.dat', 'rb') as f:
        cnn_data = pickle.load(f)

    # The file structure is ("CNN2", 0.5, acc_dict)
    # The accuracy dictionary is the 3rd element (index 2)
    cnn_acc_dict = cnn_data[2]

    # Get valid SNRs
    available_snrs = sorted(list(cnn_acc_dict.keys()))

    # --- MOCK DATA FOR CLASSICAL ML ---
    # NOTE: If you have a 'results_classical_ml.dat' file, load it here instead!
    # For now, we generate placeholder data to make the app work immediately.
    knn_acc_dict = {snr: acc * 0.6 for snr, acc in cnn_acc_dict.items()}
    svm_acc_dict = {snr: acc * 0.75 for snr, acc in cnn_acc_dict.items()}
    rf_acc_dict  = {snr: acc * 0.8 for snr, acc in cnn_acc_dict.items()}

    # Combine results
    all_results = {
        "CNN": cnn_acc_dict,
        "KNN": knn_acc_dict,
        "SVM": svm_acc_dict,
        "Random Forest": rf_acc_dict
    }

except Exception as e:
    print(f"Warning: Could not load data file. Using dummy data. Error: {e}")
    # Fallback dummy data so the app doesn't crash
    available_snrs = [-20, -10, 0, 10, 18]
    all_results = {
        "CNN": {s: 0.8 for s in available_snrs},
        "KNN": {s: 0.5 for s in available_snrs},
        "SVM": {s: 0.6 for s in available_snrs},
        "Random Forest": {s: 0.7 for s in available_snrs}
    }

# --- 2. Define the Prediction Function ---
def compare_models(snr):
    """
    Updates the table and plots based on the selected SNR.
    """
    # A. Prepare Table Data
    table_data = []
    accuracies = {}

    for model_name, snr_dict in all_results.items():
        # Get accuracy for the chosen SNR (default to 0 if missing)
        acc = snr_dict.get(snr, 0.0) * 100
        accuracies[model_name] = acc
        table_data.append([model_name, f"{acc:.2f}%"])

    df_output = pd.DataFrame(table_data, columns=["Model", "Accuracy"])

    # B. Create Bar Plot (Single SNR Comparison)
    fig_bar = plt.figure(figsize=(8, 4))
    names = list(accuracies.keys())
    values = list(accuracies.values())
    colors = ['#1f77b4' if name == 'CNN' else '#d62728' for name in names]

    bars = plt.bar(names, values, color=colors)
    plt.ylim(0, 100)
    plt.ylabel("Accuracy (%)")
    plt.title(f"Model Accuracy at SNR = {snr} dB")
    plt.grid(axis='y', alpha=0.3)

    for bar in bars:
        height = bar.get_height()
        plt.text(bar.get_x() + bar.get_width()/2., height + 1, f'{height:.1f}%', ha='center', va='bottom')

    # C. Create Line Plot (Overall Performance Curve)
    fig_line = plt.figure(figsize=(8, 4))

    # Plot line for each model
    for name, res_dict in all_results.items():
        # Sort SNRs for plotting
        sorted_snrs = sorted(res_dict.keys())
        sorted_accs = [res_dict[s] * 100 for s in sorted_snrs]

        # Style CNN differently
        if name == "CNN":
            plt.plot(sorted_snrs, sorted_accs, label=name, linewidth=3, marker='o')
        else:
            plt.plot(sorted_snrs, sorted_accs, label=name, linestyle='--', marker='x', alpha=0.7)

    # Highlight the selected SNR
    plt.axvline(x=snr, color='black', linestyle=':', label=f"Selected SNR ({snr}dB)")

    plt.xlabel("Signal-to-Noise Ratio (dB)")
    plt.ylabel("Accuracy (%)")
    plt.title(" SNR Comparison: CNN vs Classical ML")
    plt.ylim(0, 100)
    plt.legend()
    plt.grid(True, alpha=0.3)

    return df_output, fig_bar, fig_line

# --- 3. Build the Gradio Interface ---
with gr.Blocks(title="Radio Modulation Recognition") as demo:
    gr.Markdown("Compare the performance of Deep Learning (CNN) vs. Classical ML.")

    with gr.Row():
        with gr.Column(scale=1):
            # Input
            snr_selector = gr.Dropdown(
                choices=available_snrs,
                value=18 if 18 in available_snrs else available_snrs[-1],
                label="Select Signal-to-Noise Ratio (SNR) in dB"
            )

            # Output Table
            result_table = gr.Dataframe(
                headers=["Model", "Accuracy"],
                label="Detailed Results",
                interactive=False
            )

        with gr.Column(scale=2):
            # Output Plots
            bar_plot = gr.Plot(label="Current SNR Accuracy")
            line_plot = gr.Plot(label="Overall Performance Curve")

    # Interactive Logic
    snr_selector.change(fn=compare_models, inputs=snr_selector, outputs=[result_table, bar_plot, line_plot])

    # Load initial state
    demo.load(fn=compare_models, inputs=snr_selector, outputs=[result_table, bar_plot, line_plot])

# Run the app
if __name__ == "__main__":
    demo.launch(share=True)